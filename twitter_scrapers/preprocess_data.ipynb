{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "data = pd.read_csv('path to file created with consolidate_clean_data.py')\n",
    "print(len(data))\n",
    "\n",
    "# Filter by location\n",
    "US_data = data[data['location'].str.contains('Alabama|AL|Alaska|AK|Arizona|AZ|Arkansas|AR|California|CA|Colorado|CO|Connecticut|CT|Delaware|DE|Florida|FL|Georgia|GA|Hawaii|HI|Idaho|ID|Illinois|IL|Indiana|IN|Iowa|IA|Kansas|KS|Kentucky|KY|Louisiana|LA|Maine|ME|Maryland|MD|Massachusetts|MA|Michigan|MI|Minnesota|MN|Mississippi|MS|Missouri|MO|Montana|MT|Nebraska|NE|Nevada|NV|New Hampshire|NH|New Jersey|NJ|New Mexico|NM|New York|NY|North Carolina|NC|North Dakota|ND|Ohio|OH|Oklahoma|OK|Oregon|OR|Pennsylvania|PA|Rhode Island|RI|South Carolina|SC|South Dakota|SD|Tennessee|TN|Texas|TX|Utah|UT|Vermont|VT|Virginia|VA|Washington|WA|West Virginia|WV|Wisconsin|WI|Wyoming|WY')==True]\n",
    "print(len(US_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process truncated tweets\n",
    "truncated = US_data.copy()\n",
    "truncated = truncated[truncated['truncated'] == True]\n",
    "truncated = truncated[['created_at','timezone','user_id','extended_text', 'location']]\n",
    "truncated = truncated.rename(columns={'extended_text':'text'})\n",
    "print(len(truncated))\n",
    "\n",
    "truncated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process not truncated tweets\n",
    "not_trunc = US_data.copy()\n",
    "not_trunc = not_trunc[not_trunc['truncated'] == False]\n",
    "not_trunc = not_trunc[not_trunc['RT_truncated'] != False]\n",
    "not_trunc = not_trunc[not_trunc['RT_truncated'] != True]\n",
    "not_trunc = not_trunc[['created_at','timezone','user_id','text', 'location']]\n",
    "print(len(not_trunc))\n",
    "\n",
    "not_trunc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process truncated REtweets\n",
    "RT_truncated = US_data.copy()\n",
    "RT_truncated = RT_truncated[RT_truncated['RT_truncated'] == True]\n",
    "RT_truncated = RT_truncated[['created_at','timezone','user_id','extended_RT_text', 'location']]\n",
    "RT_truncated = RT_truncated.rename(columns={'extended_RT_text':'text'})\n",
    "print(len(RT_truncated))\n",
    "\n",
    "RT_truncated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process not truncated REtweets\n",
    "RT = US_data.copy()\n",
    "RT = RT[RT['RT_truncated'] == False]\n",
    "RT = RT[['created_at','timezone','user_id','RT_text', 'location']]\n",
    "RT = RT.rename(columns={'RT_text':'text'})\n",
    "print(len(RT))\n",
    "\n",
    "RT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes to get full tweets data\n",
    "full = pd.concat([truncated,not_trunc,RT_truncated,RT])\n",
    "print(len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up to extract tweet from text\n",
    "full['tweet'] = full['text']\n",
    "full['tweet'] = full['tweet'].str.replace(r'RT ', '')\n",
    "full['tweet'] = full['tweet'].str.replace(r'@([^ ]*)', '')\n",
    "full['tweet'] = full['tweet'].str.replace(r'(?= http).*$', '')\n",
    "full['tweet'] = full['tweet'].str.strip()\n",
    "\n",
    "# Get hashtags\n",
    "full['hashtags'] = full['tweet']\n",
    "full['hashtags'] = full['hashtags'].apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "\n",
    "# Get date and time\n",
    "full['date_time'] = pd.to_datetime(full['created_at'], errors='coerce')\n",
    "full['date'] = full['date_time'].dt.date\n",
    "full['time'] = full['date_time'].dt.time\n",
    "\n",
    "# Sort chronologically\n",
    "full.sort_values('date_time', inplace = True)\n",
    "\n",
    "# Keep and order desired columns\n",
    "full = full[['date', 'time', 'timezone', 'user_id', 'tweet', 'hashtags', 'location']]\n",
    "\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "full.to_csv(r'desired path to final data', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
